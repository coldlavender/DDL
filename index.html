
<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">

  <script type="text/javascript" src="//code.jquery.com/jquery-3.1.0.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
   <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.bundle.min.js" integrity="sha384-u/bQvRA/1bobcXlcEYpsEdFVK/vJs3+T+nXLsBYJthmdBuavHvAW6UsmqO2Gd/F9" crossorigin="anonymous"></script>


      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>
    
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">
   
  <link href="https://getbootstrap.com/docs/4.1/examples/navbar-fixed/navbar-top-fixed.css" rel="stylesheet" integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">

  
   
    
      <script type="text/javascript" src="https://download.affectiva.com/js/3.2/affdex.js"></script>
    
  

  <style type="text/css">
    video
    {
    	width:300px;
    	height: 230px;
    }
    #face_video
    {
      border:10px solid black
    }

    #face_video_canvas
    {
      border:10px solid black
    }

  </style>

  <title>DD學習網</title>

  <style>

/*
 * Base structure
 */

/* Move down content because we have a fixed navbar that is 50px tall */
body {
  padding-top: 50px;
}

/*
 * Typography
 */

h1 {
  margin-bottom: 20px;
  padding-bottom: 9px;
  border-bottom: 1px solid #eee;
}

/*
 * Sidebar
 */

.sidebar {
  position: fixed;
  top: 51px;
  bottom: 0;
  left: 0;
  z-index: 1000;
  padding: 20px;
  overflow-x: hidden;
  overflow-y: auto; /* Scrollable contents if viewport is shorter than content. */

}

.sidebar-right
{
  height:100%;
  position:fixed;
  right:0;
}

/* Sidebar navigation */
.sidebar {

}

.sidebar .nav {
  margin-bottom: 20px;
}

.sidebar .nav-item {
  width: 100%;
}

.sidebar .nav-item + .nav-item {
  margin-left: 0;
}

.sidebar .nav-link {
  border-radius: 0;
}

/*
 * Dashboard
 */

 /* Placeholders */
.placeholders {
  padding-bottom: 3rem;
}

.placeholder img {
  padding-top: 1.5rem;
  padding-bottom: 1.5rem;
}
  </style>
</head>

<body>
    <nav class="navbar navbar-expand-md fixed-top bg-light">
  <div class="container">
         <a class="navbar-brand" href="#">DD學習網 </a>
<button type="button" class="btn btn-light">
	<i class="fas fa-book"></i>

課程</button>
<button type="button" class="btn btn-light">
			<i class="fas fa-trophy"></i>
成就</button>
<button type="button" class="btn btn-light">
		<i class="fas fa-cogs"></i>
設定</button>
<button type="button" class="btn btn-light">
				<i class="fas fa-question-circle"></i>
導覽</button>
<button type="button" class="btn btn-light">
<i class="fas fa-clipboard-check"></i>
問卷</button>

<img width="200px" src="ddlab-logo-out-05.png" />

  </div>
</nav>
  <div class="container-fluid">
    <div class="row">

      <nav class="col-md-2 sidebar" id="left" style="">
            <div class="">
<br><br>      	<p>

          ch1<br>
      	康丁斯基簡介
      	<br>
      </p>

	<p>ch2<br>
      	康丁斯基各分期
      	<br>
      </p>
      

      	<p>ch3<br>
      	康丁斯基作品介紹

      	<br>
      </p>
      </div>

      </nav>
      <div class="col-sm-7 offset-sm-2 col-md-7 offset-md-2 pt-3" id="reading" style="">
<br><br>


康定斯基：「顏色是琴鍵，眼睛是琴槌，靈魂是鋼琴的琴絃。藝術家就是演奏的手，撫弄著一個又一個琴鍵，讓靈魂震顫。」（Colour is the keyboard, the eyes are the hammers, the soul is the piano with many strings.The artist is the hand that plays,touching one key or another, to cause vibrations in the soul.)
<br><br>


瓦西里·康定斯基（Wassily Kandinsky，1866-1944）是二十世紀抽象表現主義藝術代表人物及理論大師，也是聯覺藝術（Synesthesia in art）代表性的藝術家。美術學家Hajo Duechting曾依照藝術特徵，將康丁斯基的創作分為六個時期：初期（莫斯科，1866-1896）、變形（慕尼黑，1896-1911）、抽象的突破（藍騎士， 1911-1914）、俄羅斯間奏曲（1914-1921）、點線面（包浩斯，1922-1933）、生物的抽象（巴黎，1934-1944）。
<br><br>

康丁斯基﹝Wassily Kandinsky﹞﹝1866 ~ 1944﹞生於莫斯科，早年學習了鋼琴和大提琴， 這對於他後來嘗試將音樂展現在畫布有絕對的影響。他在近三十歲時，受到莫內﹝Claude Monet﹞的啟發，毅然決定從當法律教師的工作改當畫家。 二十世紀初，康丁斯基到慕尼黑學習印象派繪畫，和當時新興的畫風。在 1900 年到 1910 年這段期間，他四處旅遊，先後去了威尼斯、突尼斯、荷蘭、法國和俄國，一路吸收印象主 義和未來主義的繪畫風格，從此對純粹顏色的力量有了自己的概念。康丁斯基強調純色的心 理效果，強調鮮紅顏色怎樣像號聲一樣使人動心，他相信通過這種觀念創作，進行心靈與心 靈之間交流是可能而且必要的。 1911 年之後，康丁斯基陸續結識馬蒂斯和克利等人一起創立表現主義團體「藍騎士」 ﹝Blue Rider﹞，並且共同辦畫展，也因為有他們的推動，表現主義得以盡情的發展。到了 20 年代，康丁斯基的作品有很大的改變，由早期的浪漫式幻想轉為幾何圖形的構圖。1922 年， 他到包浩斯﹝Bauhaus﹞設計學院當教員時，正是他藝術創作的高潮時期。康定斯基對於包浩斯設計學院基礎課程的貢獻有兩個方面，包括分析繪畫和對色彩與形體的理論研究。他要求 學生設計色彩與形體的單體，然後把這些單體進行不同的組合，從中研究形體與色彩的結構 方式和產生的藝術效果。他的教學是從完全抽象的色彩形體理論開始，然後逐步把這些抽象 的內容與具體的設計聯系起來。 康丁斯基在他後期的創作中，融合了自己早期直覺式的畫風和後來的幾何圖形風格，這 些無疑為他的作品增添了一種新的理念。他是一位能將色彩與音樂等同起來的畫家，讓人們 能夠「聆聽」繪畫，「描繪」音樂。
<br><br>

二、音樂與繪畫的關係 


<br><br>

（一）共感覺(Synesthesia) 林書堯（1977）在《色彩認識論》一書中說明，所謂共感覺就是任何一個感覺系統受到 刺激之後，會立即引起該系統的直接反應之外，尚會引起除了直屬系統（第一次感覺）以外， 一連串的其他感覺系統（第二次感覺）的共鳴現象，所以說共感覺就是在這種狀況下產生。 所謂的「共感覺」就是說當一種型態對人的感覺刺激，會引起一種或一種以上的感覺反 應。在繪畫藝術表現共感覺形式，如俄國抽象派畫家康丁斯基(Kandinsky1866-1944)，他看到 形狀會產生顏色聯想：如三角形是黃色，正方形是紅色，圓形是藍色等等，他在這種形狀與 顏色的相對關係，時常反映在他的繪畫表現之中。康丁斯基也非常喜愛音樂，他認為色彩的 流動就像是音樂的流動一般，所以他的藝術作品名稱時常就是音樂的名稱，如畫名 Composition no.X (作品 X 號) ，或就叫做 Improvisation (即興)。
<br><br>

（二）聲音與色彩 聲音樂色彩的問題根據畢達格拉斯的顏色與音樂理論，已經確定在七種光譜色與七種音 階之間存在著可比振動頻率；聲音與色彩的關係我們也可以回朔至17 世紀時期英國物理學家 牛頓（SirIsaac Newton），他將色彩與音樂中的音階做一對應關係：紅、橙、黃、綠、藍、靛、 紫等七種顏色，對應到音樂依序為Do（C）、Re（D）、Mi（E）、Fa（F）、Sol（G）、La （A）、Si（B）等七音。 康丁斯基對於聲音與色彩的關係，指出我們能從音樂中「聽見」顏色，也能從色彩中「看 到」聲音，他指出黃色如同小喇叭一般，具有一種特殊能力，可以愈吹『升』愈高，達到眼 睛和精神所無法忍受的高度，會變得非常的『尖銳』，甚至能刺痛耳朵。而藍色剛好有相反的 效果，會讓人們『降到』無限的深，以其雄偉的低音而發出橫笛(淺藍色時)、大提琴(降得更 低時)、低音提琴的音色。當我們看到綠色時，會顯得非常的平衡感，如同小提琴中段和漸細 的音色。而紅色(硃砂色)可以給予強烈鼓聲的印象。
<br><br>

（三）音樂與形態 英國劍橋大學教授馬堯司（C.S.Myers）的實驗音樂的移情可分為四類：主觀類、聯想類、 客觀類、性格類，從上可知人類的移情會因經驗的不同而有差異。根據《時代》雜誌2001年 報導「中央大學杜尚（Sean Day）副教授聽到幽悽的薩克風樂音時，會看到一坨霓紅紫的蛇 在空中扭舞，口琴聲是愉悅的綠色，鋼琴聲的敲擊漫溢出藍色的薄霧。」（阮綠茵，2003） 康丁斯基在《點線面》中提到：「古老芭蕾舞蹈型式中就有「點」這個術語，踮著腳尖走 路，身後留下的就是一串串的點」。舞者聽著音樂而舞動，透過身體各部位的形態，表現出音 樂的感覺。康丁斯基認為人在舞蹈時，整個身體的舞動就是在畫圖，每一個指頭都有豐富的 表情，舞者在舞台上，非常精確的將音樂的旋律透過線條表現出來。 「音樂的媒材是曲調、合聲、節奏以及音色與結構，而繪畫的媒材是色彩與線條，此二 項藝術各有其機能、要素、氣質與效果，各自有獨立的領域，然而彼此之間亦有相當程度的 共通性、串聯性與感通性。」（楊嘉玲，2001） 三、康丁斯基的音樂繪畫概念 （一）抽象繪畫概念 康丁斯基視「內在需要」為原則，主要來自「個性的」、「風格的」、「藝術的目標性」三 個因素。藝術家意圖尋求一個具安定與永恆的力量、更能觸及「真實」的藝術語言，而抽象 藝術則回應了這些要求。 

<br><br>


（二）藝術的精神性 康丁斯基在 1912 年出版《藝術的精神性》一書，奠定了抽象藝術的精神性，康丁斯基重 視忠於內在精神的藝術形式，此書則敘述了自己對「精神性」的強調，以及從音樂說明他的 藝術哲學，藉由抽象繪畫越來越接近音樂本質之絕對的創造，使作品在沒有任何形體參照下， 由自身衍生獨立意義。
<br><br>

（三）繪畫的音樂性 康丁斯基認為繪畫與音樂並沒有分別，他們都是一種溝通，如同音樂之旋律（樂音）直 接訴諸心靈（不必靠歌詞），色彩與形勢也能夠成足以表達之語言。而抽象藝術表現的音樂每、 節奏感、韻律感，可以說主要就是藉由點、線、面、形和色等媒材因素結合與安排出來。
<br><br>


      </div>

      <div class="col-md-3 sidebar-right "  style="">
<br><br>
<br>
<br>
<br>

      <p id="bot" style="text-align:center" > <img data-toggle="popover" data-placement="top" title="" data-content="吃飽沒？" id="bot_img" style="width:150px;" src="emotion/normal_a.gif"></p>
      <br><br>
      <div id="affdex_elements" style=""></div>
  

<br>
    <div class="form-group">
  <input type="text" class="form-control" placeholder="請輸入你的想法..." id="input_text">
</div>
</div>

<hr> 
    <div class="row" style="display:none">

    <div class="col-md-12">
        <div style="height:30em;">
          <strong>EMOTION TRACKING RESULTS</strong>
          <div id="results" style="word-wrap:break-word;"></div>
        </div>
        <div>
          <strong>DETECTOR LOG MSGS</strong>
        </div>
        <div id="logs"></div>
      </div>
    </div>

    <div>

<!--
      <button id="start" onclick="onStart()">Start</button>
      <button id="stop" onclick="onStop()">Stop</button>
      <button id="reset" onclick="onReset()">Reset</button>
      <h3>Affectiva JS SDK CameraDetector to track different emotions.</h3>
      <p>
        <strong>Instructions</strong>
        </br>
        Press the start button to start the detector.
        <br/> When a face is detected, the probabilities of the different emotions are written to the DOM.
        <br/> Press the stop button to end the detector.
      </p>
        -->

    </div>
  </div>
</body>

  













<script type="text/javascript">


      // SDK Needs to create video and canvas nodes in the DOM in order to function
      // Here we are adding those nodes a predefined div.
      var divRoot = $("#affdex_elements")[0];
      var width = 300;
      var height = 230;
      var talk = ['吃飽未？','我也這麼覺得','真的嗎？','你確定？','也是','嗯嗯','...','呵呵','喵喵喵喵','？？？']
      var faceMode = affdex.FaceDetectorMode.LARGE_FACES;

      var emo_file = ['happy','sad','disgust','frustration','anger','fear','surprised']


      var face_emotion=[];
      for (var i = 0; i < face_emotion.length; i++) {
      	face_emotion[i]=0
      };
      //Construct a CameraDetector and specify the image width / height and face detector mode.
      var detector = new affdex.CameraDetector(divRoot, width, height, faceMode);

      //Enable detection of all Expressions, Emotions and Emojis classifiers.
      detector.detectAllEmotions();
      detector.detectAllExpressions();
      detector.detectAllEmojis();
      detector.detectAllAppearance();

      //Add a callback to notify when the detector is initialized and ready for runing.
      detector.addEventListener("onInitializeSuccess", function() {
        log('#logs', "The detector reports initialized");
        //Display canvas instead of video feed because we want to draw the feature points on it
        $("#face_video_canvas").css("display", "block");
        $("#face_video").css("display", "none");
      });

      // A $( document ).ready() block.
$( document ).ready(function() {
    console.log( "ready!" );
    onStart()
    setInterval(bot_stat, 3000);

    $('#input_text').on('keydown', function(e) {
    if (e.which == 13) {
    	console.log($('#input_text').val())
    	bot_chat($('#input_text').val())
    	$('#input_text').val("")
        e.preventDefault();
    }
});

$(function () {
  $('[data-toggle="popover"]').popover()
})


});

function bot_chat (text) {
	// body...
	  $("#bot_img").attr("data-content",talk[ Math.floor((Math.random() * talk.length)) ])

	  $('#bot_img').popover('show')


}

function bot_stat () {
	// body...
		  $('#bot_img').popover('hide')

	var top_i=0, top_val=0;
	for (var i = 0; i <=6; i++) {
		if(face_emotion[i]>Math.abs(top_val))
		{
			top_val = face_emotion[i]
			top_i=i
		}


	};
	if(top_val==0) //沒臉部表情
	{
		if (  Math.floor((Math.random() * 2) +1)==1) 
		{
		$("#bot_img").attr("src","emotion/"+'normal_a'+".gif")
		}
		else
		{
					$("#bot_img").attr("src","emotion/"+'normal_b'+".gif")
		}
	}
	else{
		$("#bot_img").attr("src","emotion/"+emo_file[ top_i ]+".gif")
	}
	console.log(emo_file[ top_i ])
}
      function log(node_name, msg) {
        $(node_name).append("<span>" + msg + "</span><br />")
      }

      //function executes when Start button is pushed.
      function onStart() {
        if (detector && !detector.isRunning) {
          $("#logs").html("");
          detector.start();
        }
        log('#logs', "Clicked the start button");
      }

      //function executes when the Stop button is pushed.
      function onStop() {
        log('#logs', "Clicked the stop button");
        if (detector && detector.isRunning) {
          detector.removeEventListener();
          detector.stop();
        }
      };

      //function executes when the Reset button is pushed.
      function onReset() {
        log('#logs', "Clicked the reset button");
        if (detector && detector.isRunning) {
          detector.reset();

          $('#results').html("");
        }
      };

      //Add a callback to notify when camera access is allowed
      detector.addEventListener("onWebcamConnectSuccess", function() {
        log('#logs', "Webcam access allowed");
      });

      //Add a callback to notify when camera access is denied
      detector.addEventListener("onWebcamConnectFailure", function() {
        log('#logs', "webcam denied");
        console.log("Webcam access denied");
      });

      //Add a callback to notify when detector is stopped
      detector.addEventListener("onStopSuccess", function() {
        log('#logs', "The detector reports stopped");
        $("#results").html("");
      });

      //Add a callback to receive the results from processing an image.
      //The faces object contains the list of the faces detected in an image.
      //Faces object contains probabilities for all the different expressions, emotions and appearance metrics
      detector.addEventListener("onImageResultsSuccess", function(faces, image, timestamp) {
        $('#results').html("");
        log('#results', "Timestamp: " + timestamp.toFixed(2));
        log('#results', "Number of faces found: " + faces.length);
        if (faces.length > 0) {

        	var ii=0;

        	var val = faces[0].emotions['joy']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['sadness']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['disgust']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['contempt']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['anger']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['fear']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['surprise']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['valence']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['engagement']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;



          log('#results', "Appearance: " + JSON.stringify(faces[0].appearance));
          log('#results', "Emotions: " + JSON.stringify(faces[0].emotions, function(key, val) {
            return val.toFixed ? Number(val.toFixed(0)) : val;
          }));
          log('#results', "Expressions: " + JSON.stringify(faces[0].expressions, function(key, val) {
            return val.toFixed ? Number(val.toFixed(0)) : val;
          }));
          log('#results', "Emoji: " + faces[0].emojis.dominantEmoji);
          drawFeaturePoints(image, faces[0].featurePoints);
        }
      });

      //Draw the detected facial feature points on the image
      function drawFeaturePoints(img, featurePoints) {
        var contxt = $('#face_video_canvas')[0].getContext('2d');

        var hRatio = contxt.canvas.width / img.width;
        var vRatio = contxt.canvas.height / img.height;
        var ratio = Math.min(hRatio, vRatio);

        contxt.strokeStyle = "#FFFFFF";
        for (var id in featurePoints) {
          contxt.beginPath();
          contxt.arc(featurePoints[id].x,
            featurePoints[id].y, 2, 0, 2 * Math.PI);
          contxt.stroke();

        }
      }







</script>

  <script>
  // tell the embed parent frame the height of the content
  if (window.parent && window.parent.parent){
    window.parent.parent.postMessage(["resultsFrame", {
      height: document.body.getBoundingClientRect().height,
      slug: "None"
    }], "*")
  }
</script>

</body>

</html>

