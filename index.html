
<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">

  <script type="text/javascript" src="//code.jquery.com/jquery-3.1.0.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js" integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T" crossorigin="anonymous"></script>
   <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.bundle.min.js" integrity="sha384-u/bQvRA/1bobcXlcEYpsEdFVK/vJs3+T+nXLsBYJthmdBuavHvAW6UsmqO2Gd/F9" crossorigin="anonymous"></script>


      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"></script>
    
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB" crossorigin="anonymous">
   
  <link href="https://getbootstrap.com/docs/4.1/examples/navbar-fixed/navbar-top-fixed.css" rel="stylesheet"  crossorigin="anonymous">

  
   
    
      <script type="text/javascript" src="https://download.affectiva.com/js/3.2.1/affdex.js"></script>
    
  

  <style type="text/css">
    video
    {
    	width:300px;
    	height: 230px;
    }
    #face_video
    {
      border:10px solid black
    }

    #face_video_canvas
    {
      border:10px solid black
    }

  </style>

  <title>DD學習網</title>

  <style>

/*
 * Base structure
 */

/* Move down content because we have a fixed navbar that is 50px tall */
body {
  padding-top: 50px;
}

/*
 * Typography
 */

h1 {
  margin-bottom: 20px;
  padding-bottom: 9px;
  border-bottom: 1px solid #eee;
}

/*
 * Sidebar
 */

.sidebar {
  position: fixed;
  top: 51px;
  bottom: 0;
  left: 0;
  z-index: 1000;
  padding: 20px;
  overflow-x: hidden;
  overflow-y: auto; /* Scrollable contents if viewport is shorter than content. */

}

.sidebar-right
{
  height:100%;
  position:fixed;
  right:0;
}

/* Sidebar navigation */
.sidebar {

}

.sidebar .nav {
  margin-bottom: 20px;
}

.sidebar .nav-item {
  width: 100%;
}

.sidebar .nav-item + .nav-item {
  margin-left: 0;
}

.sidebar .nav-link {
  border-radius: 0;
}

/*
 * Dashboard
 */

 /* Placeholders */
.placeholders {
  padding-bottom: 3rem;
}

.placeholder img {
  padding-top: 1.5rem;
  padding-bottom: 1.5rem;
}
  </style>
</head>

<body>
    <nav class="navbar navbar-expand-md fixed-top bg-light">
  <div class="container">
         <a class="navbar-brand" href="#">DD學習網 </a>
<button type="button" class="btn btn-light">
	<i class="fas fa-book"></i>

課程</button>
<button type="button" class="btn btn-light">
			<i class="fas fa-trophy"></i>
成就</button>
<button type="button" class="btn btn-light">
		<i class="fas fa-cogs"></i>
設定</button>
<button type="button" class="btn btn-light">
				<i class="fas fa-question-circle"></i>
導覽</button>
<button type="button" class="btn btn-light">
<i class="fas fa-clipboard-check"></i>
問卷</button>

<img width="200px" src="ddlab-logo-out-05.png" />

  </div>
</nav>
  <div class="container-fluid">
    <div class="row">

      <nav class="col-md-2 sidebar" id="left" style="">
            <div class="">
課程目錄<br>    	


<p class="btn btn-light" onclick="change_class('c1')" >

        ch1<br>
      	文藝復興
      	<br>
      </p>

	<p class="btn btn-light" onclick="change_class('c2')" >ch2<br>
      	巴洛克時期
      	<br>
      </p>
      

      	<p class="btn btn-light" onclick="change_class('c3')">ch3<br>
      	古典時期

      	<br>
      </p>

  <p class="btn btn-light" onclick="change_class('c4')" >ch4+5<br>
        浪漫時期
        <br>
      </p>
  <p class="btn btn-light" onclick="change_class('c7')" >ch7+8+9<br>
        現代音樂
        <br>
      </p>
  <p class="btn btn-light" onclick="change_class('c10')" >ch10<br>
        電影音樂
        <br>
      </p>      
  <p class="btn btn-light" onclick="change_class('c11')" >ch11<br>
        新世紀音樂
        <br>
      </p>
  <p class="btn btn-light" onclick="change_class('c12')" >ch12+13+14<br>
        數位音樂
        <br>
      </p>
  
      </div>

      </nav>
      <div class="col-sm-7 offset-sm-2 col-md-7 offset-md-2 pt-3" id="reading" style="">
<br><br>




      </div>

      <div class="col-md-3 sidebar-right "  style="">
<br><br>
<br>
<br>
<br>

      <p id="bot" style="text-align:center" > <img data-toggle="popover" data-placement="top" title="" data-content="吃飽沒？" id="bot_img" style="width:150px;" src="emotion/normal_a.gif"></p>
      <br><br>
      <div id="affdex_elements" style=""></div>
  

<br>
    <div class="form-group">
  <input type="text" class="form-control" placeholder="請輸入你的想法..." id="input_text">
</div>
</div>

<hr> 
    <div class="row" style="display:none">

    <div class="col-md-12">
        <div style="height:30em;">
          <strong>EMOTION TRACKING RESULTS</strong>
          <div id="results" style="word-wrap:break-word;"></div>
        </div>
        <div>
          <strong>DETECTOR LOG MSGS</strong>
        </div>
        <div id="logs"></div>
      </div>
    </div>

    <div>

<!--
      <button id="start" onclick="onStart()">Start</button>
      <button id="stop" onclick="onStop()">Stop</button>
      <button id="reset" onclick="onReset()">Reset</button>
      <h3>Affectiva JS SDK CameraDetector to track different emotions.</h3>
      <p>
        <strong>Instructions</strong>
        </br>
        Press the start button to start the detector.
        <br/> When a face is detected, the probabilities of the different emotions are written to the DOM.
        <br/> Press the stop button to end the detector.
      </p>
        -->

    </div>
  </div>
</body>

  













<script type="text/javascript">


      // SDK Needs to create video and canvas nodes in the DOM in order to function
      // Here we are adding those nodes a predefined div.
      var divRoot = $("#affdex_elements")[0];
      var width = 300;
      var height = 230;
      var talk = ['吃飽未？','我也這麼覺得','真的嗎？','你確定？','也是','嗯嗯','...','呵呵','喵喵喵喵','？？？']
      var faceMode = affdex.FaceDetectorMode.LARGE_FACES;

      var emo_file = ['happy','sad','disgust','frustration','anger','fear','surprised']



      var face_emotion=[];
      for (var i = 0; i < face_emotion.length; i++) {
      	face_emotion[i]=0
      };
      //Construct a CameraDetector and specify the image width / height and face detector mode.
      var detector = new affdex.CameraDetector(divRoot, width, height, faceMode);

      //Enable detection of all Expressions, Emotions and Emojis classifiers.
      detector.detectAllEmotions();
      detector.detectAllExpressions();
      detector.detectAllEmojis();
      detector.detectAllAppearance();

      //Add a callback to notify when the detector is initialized and ready for runing.
      detector.addEventListener("onInitializeSuccess", function() {
        log('#logs', "The detector reports initialized");
        //Display canvas instead of video feed because we want to draw the feature points on it
        $("#face_video_canvas").css("display", "block");
        $("#face_video").css("display", "none");
      });

      // A $( document ).ready() block.
$( document ).ready(


  function() {
    console.log( "ready!" );
    onStart()
    setInterval(bot_stat, 3000);

    $('#input_text').on('keydown', function(e) {
    if (e.which == 13) {
    	console.log($('#input_text').val())
    	bot_chat($('#input_text').val())
    	$('#input_text').val("")
        e.preventDefault();
    }
});

$(function () {
  $('[data-toggle="popover"]').popover()
})


///
$("#reading").load("/class/c1.htm");

///

});

function change_class (text) {
  $("#reading").load("/class/"+text+".htm");
}
 function jsonpCallback(data){
     //   console.log(data)
    }
function bot_chat (text) {
	// body...




$.ajax({
        url: "http://34.80.209.224/get?msg="+text+"?callback=?",
        dataType: "jsonp",
        jsonp: "callback",
        jsonpCallback: "jsonpCallback",
        success: function(json){
          //jQuery會自動將結果傳入(如果有設定callback函式的話，兩者都會執行)
          console.log(json.data);

          $("#bot_img").attr("data-content", json.data);

          $('#bot_img').popover('show')


        },
        error: function(){
          alert('fail');
        }
    })



	 // $("#bot_img").attr("data-content",talk[ Math.floor((Math.random() * talk.length)) ])
 


}

function bot_stat () {
	// body...
		 // $('#bot_img').popover('hide')

	var top_i=0, top_val=0;
	for (var i = 0; i <=6; i++) {
		if(face_emotion[i]>Math.abs(top_val))
		{
			top_val = face_emotion[i]
			top_i=i
		}


	};
	if(top_val==0) //沒臉部表情
	{
		if (  Math.floor((Math.random() * 2) +1)==1) 
		{
		$("#bot_img").attr("src","emotion/"+'normal_a'+".gif")
		}
		else
		{
					$("#bot_img").attr("src","emotion/"+'normal_b'+".gif")
		}
	}
	else{
		$("#bot_img").attr("src","emotion/"+emo_file[ top_i ]+".gif")
	}
	console.log(emo_file[ top_i ])
}
      function log(node_name, msg) {
        $(node_name).append("<span>" + msg + "</span><br />")
      }

      //function executes when Start button is pushed.
      function onStart() {
        if (detector && !detector.isRunning) {
          $("#logs").html("");
          detector.start();
        }
        log('#logs', "Clicked the start button");
      }

      //function executes when the Stop button is pushed.
      function onStop() {
        log('#logs', "Clicked the stop button");
        if (detector && detector.isRunning) {
          detector.removeEventListener();
          detector.stop();
        }
      };

      //function executes when the Reset button is pushed.
      function onReset() {
        log('#logs', "Clicked the reset button");
        if (detector && detector.isRunning) {
          detector.reset();

          $('#results').html("");
        }
      };

      //Add a callback to notify when camera access is allowed
      detector.addEventListener("onWebcamConnectSuccess", function() {
        log('#logs', "Webcam access allowed");
      });

      //Add a callback to notify when camera access is denied
      detector.addEventListener("onWebcamConnectFailure", function() {
        log('#logs', "webcam denied");
        console.log("Webcam access denied");
      });

      //Add a callback to notify when detector is stopped
      detector.addEventListener("onStopSuccess", function() {
        log('#logs', "The detector reports stopped");
        $("#results").html("");
      });

      //Add a callback to receive the results from processing an image.
      //The faces object contains the list of the faces detected in an image.
      //Faces object contains probabilities for all the different expressions, emotions and appearance metrics
      detector.addEventListener("onImageResultsSuccess", function(faces, image, timestamp) {
        $('#results').html("");
        log('#results', "Timestamp: " + timestamp.toFixed(2));
        log('#results', "Number of faces found: " + faces.length);
        if (faces.length > 0) {

        	var ii=0;

        	var val = faces[0].emotions['joy']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['sadness']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['disgust']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['contempt']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['anger']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['fear']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['surprise']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['valence']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;
        	var val = faces[0].emotions['engagement']
        	face_emotion[ii++]=val.toFixed ? Number(val.toFixed(0)) : val;



          log('#results', "Appearance: " + JSON.stringify(faces[0].appearance));
          log('#results', "Emotions: " + JSON.stringify(faces[0].emotions, function(key, val) {
            return val.toFixed ? Number(val.toFixed(0)) : val;
          }));
          log('#results', "Expressions: " + JSON.stringify(faces[0].expressions, function(key, val) {
            return val.toFixed ? Number(val.toFixed(0)) : val;
          }));
          log('#results', "Emoji: " + faces[0].emojis.dominantEmoji);
          drawFeaturePoints(image, faces[0].featurePoints);
        }
      });

      //Draw the detected facial feature points on the image
      function drawFeaturePoints(img, featurePoints) {
        var contxt = $('#face_video_canvas')[0].getContext('2d');

        var hRatio = contxt.canvas.width / img.width;
        var vRatio = contxt.canvas.height / img.height;
        var ratio = Math.min(hRatio, vRatio);

        contxt.strokeStyle = "#FFFFFF";
        for (var id in featurePoints) {
          contxt.beginPath();
          contxt.arc(featurePoints[id].x,
            featurePoints[id].y, 2, 0, 2 * Math.PI);
          contxt.stroke();

        }
      }







</script>

  <script>
  // tell the embed parent frame the height of the content
  if (window.parent && window.parent.parent){
    window.parent.parent.postMessage(["resultsFrame", {
      height: document.body.getBoundingClientRect().height,
      slug: "None"
    }], "*")
  }
</script>

</body>

</html>

